# B-Tree (arbol B)

Los B-Trees son ABBs balanceados diseñados para trabajar bien en discos, u otros dispositivos de almacenamiento secundarios de acceso directo. Los B-Trees son similares a los Red-Black trees, pero ellos son mejores minimizando las operaciones de I/O del disco. Muchos sistemas de bases de datos usan B-Trees, o variantes de B-Trees, par almacenar informacion.

Los B-trees, a diferencia de los Red-black trees, tienen nodos con muchos hijos, de unos pocos a unos miles. "The branching factor" (factor de ramificacion), de un B-Tree puede ser muy grande, a pesar de que usualmente depende de las caracteristicas de la unidad de disco utilizada. Los B-trees son similares a los red-black trees respecto a que cada B-tree de n-nodos tiene una altura *O(log n)*. La altura exacta de un B-tree puede ser considerablemente menor a la de un red-black tree, sin embargo, a causa del factor de ramificacion, y por lo tanto la base del logaritmo que expresa la altura puede ser mucho mayor. Por lo tanto, podemos usar B-trees para implementar muchas operaciones de conjuntos dinamicos en tiempo *O(log n)*.

Los B-trees generalizan a los ABBs de forma natural. Si en un B-tree un nodo interno *x* contiene *n.x* claves, entonces *x* tiene *n.x + 1* hijos. Las claves en el nodo *x* sirven como puntos de division que separan el rango de claves manejadas por xintox: subrangos *x.n + 1*, cada uno manejado por un hijo de *x*. Cuando se busca una clave en un B-tree, tomamos (*x.n*+1) decisiones basadas en comparaciones con *x.n* llaves almacenadas en el nodo *x*. La estructura de los nodos hoja difiere de la del nodo interno.

### Estructuras de datos en almacenamiento secundario

Los sistemas de computacion toman la ventaja de varias tecnologias que proveen memoria y capacidad. La **memoria primaria** (o **memoria principal**) de un sistema de computadora normalmente consiste de chips de memoria de silicio. Esta tecnología suele ser más de un orden de magnitud más cara por bit almacenado que la tecnología de almacenamiento magnético, como cintas o discos. La mayoria de los sistemas informaticos tienen ademas un **almacenamiento secundario** basado en discos magneticos; la cantidad de dicho almacenamiento secundario a menudo excede la cantidad de memoria primaria en al menos dos órdenes de magnitud.

La unidad consta de una o más **placas**, que giran a una velocidad constante alrededor de un **eje** común. Un material magnetizable cubre la superficie de cada plato. La unidad lee y escribe cada plato con la **cabeza** al final de un **brazo**. Los brazos pueden mover sus cabezas hacia o lejos del eje. Cuando una cabeza determinada está estacionaria, la superficie que pasa por debajo se llama **atraco**. Varios platos aumentan solo la capacidad de la unidad de disco y no su rendimiento.

Aunque los discos son más baratos y tienen mayor capacidad que la memoria principal, son mucho, mucho más lentos porque tienen partes mecánicas móviles.1 El movimiento mecánico tiene dos componentes: rotación del plato y movimiento del brazo. Al momento de escribir este artículo, los discos básicos giran a velocidades de 5400-15000 revoluciones por minuto (RPM). Normalmente vemos velocidades de 15000 RPM en unidades de nivel de servidor, velocidades de 7200 RPM en unidades para computadoras de escritorio y velocidades de 5400 RPM en unidades para computadoras portátiles. Aunque 7200 RPM puede parecer rápido, una rotación toma 8,33 milisegundos, que es más de 5 órdenes de magnitud más que los tiempos de acceso de 50 nanosegundos (más o menos) que se encuentran comúnmente para la memoria de silicio. En otras palabras, si tenemos que esperar una rotación completa para que un elemento en particular pase bajo el cabezal de lectura / escritura, podríamos acceder a la memoria principal más de 100,000 veces durante ese lapso. En promedio, tenemos que esperar solo media rotación, pero aún así, la diferencia en los tiempos de acceso para la memoria de silicio en comparación con los discos es enorme. Mover los brazos también lleva algún tiempo. En el momento de redactar este documento, los tiempos de acceso promedio para los discos básicos están en el rango de 8 a 11 milisegundos.

Para amortizar el tiempo de espera de los movimientos mecánicos, los discos acceden no solo a un elemento, sino a varios a la vez. La información se divide en un número de páginas de bits de igual tamaño que aparecen consecutivamente dentro de las pistas, y cada lectura o escritura de disco es de una o más páginas completas. Para un disco típico, una página puede tener de 2^11 a 2^14 bytes de longitud. Una vez que el cabezal de lectura / escritura está colocado correctamente y el disco ha girado al principio de la página deseada, la lectura o escritura de un disco magnético es completamente electrónica (aparte de la rotación del disco), y el disco puede leer o escribir rápidamente grandes cantidades de datos.

A menudo, acceder a una página de información y leerla desde un disco lleva más tiempo que examinar toda la información leída. Por esta razón, en este capítulo veremos por separado los dos componentes principales del tiempo de ejecución:

- el numero de accesos al disco, y
- el tiempo de CPU (computo).

Medimos la cantidad de accesos al disco en términos de la cantidad de páginas de información que deben leerse o escribirse en el disco. Observamos que el tiempo de acceso al disco no es constante, depende de la distancia entre la pista actual y la pista deseada y también de la posición de rotación inicial del disco. No obstante, utilizaremos el número de páginas leídas o escritas como una aproximación de primer orden del tiempo total dedicado a acceder al disco.

En una aplicación típica de árbol B, la cantidad de datos que se manejan es tan grande que todos los datos no caben en la memoria principal a la vez. Los algoritmos de árbol B copian las páginas seleccionadas del disco a la memoria principal según sea necesario y escriben de nuevo en el disco las páginas que han cambiado. Los algoritmos de árbol B mantienen solo un número constante de páginas en la memoria principal en cualquier momento; por lo tanto, el tamaño de la memoria principal no limita el tamaño de los árboles B que se pueden manejar.

Modelamos las operaciones de disco en nuestro pseudocódigo de la siguiente manera. Sea un puntero a un objeto. Si el objeto se encuentra actualmente en la memoria principal de la computadora, entonces podemos referirnos a los atributos del objeto como de costumbre: x.key, por ejemplo. Sin embargo, si el objeto referido porx reside en el disco, entonces debemos realizar la operación DISK-READ(x) para leer el objetox en la memoria principal antes de poder referirnos a sus atributos. (Suponemos que ifxis ya está en la memoria principal, entonces DISK-READ(x) no requiere accesos de disco; es un "no-op.") De manera similar, la operación DISK-WRITE(x) se usa para guardar cualquier cambio que haya hecho a los atributos del objeto x. Es decir, el patrón típico para trabajar con un objeto es el siguiente:

```
x = a pointer to some object
DISK-READ(x)
operations that access and/or modify the attributes of x
DISK-WRITE.x    ///omitted if no attributes of x were changed
other operations that access but do not modify attributes of x
```

El sistema puede mantener solo un número limitado de páginas en la memoria principal al mismo tiempo. Supondremos que el sistema se vacía de las páginas de la memoria principal que ya no se utilizan; Nuestros algoritmos de árbol B ignorarán este problema. Dado que en la mayoría de los sistemas el tiempo de ejecución de un algoritmo de árbol B depende principalmente del número de operaciones DISK-READ y DISK-WRITE que realiza, normalmente queremos que cada una de estas operaciones lea o escriba tanta información como sea posible. Por lo tanto, un nodo de árbol B suele ser tan grande como una página de disco completa, y este tamaño limita la cantidad de hijos que puede tener un nodo de árbol B. Para un árbol B grande almacenado en un disco, a menudo vemos factores de ramificación entre 50 y 2000, dependiendo del tamaño de una clave en relación con el tamaño de una página. Un factor de ramificación grande reduce drásticamente tanto la altura del árbol como el número de accesos al disco necesarios para encontrar cualquier clave. La figura 18.3 muestra un árbol B con un factor de ramificación de 1001 y altura2 que puede almacenar más de mil millones de claves; no obstante, dado que podemos mantener el nodo raíz de forma permanente en la memoria principal, podemos encontrar cualquier clave en este árbol haciendo como máximo solo dos accesos al disco.

## Definicion de B-Trees

Para simplificar las cosas, asumimos, como hemos hecho con los árboles de búsqueda binarios y los árboles rojo-negro, que cualquier "información de satélite" asociada con una clave reside en el mismo nodo que la clave. En la práctica, uno podría almacenar con cada tecla solo un puntero a otra página de disco que contiene la información de satélite para esa tecla. El pseudocódigo de este capítulo asume implícitamente que la información de satélite asociada con una clave, o el puntero a dicha información de satélite, viaja con la clave siempre que la clave se mueve de un nodo a otro. Una variante común en un árbol B, conocida como árbol B +, almacena toda la información del satélite en las hojas y almacena solo claves y punteros secundarios en los nodos internos, maximizando así el factor de ramificación de los nodos internos.

Un árbol B T es un árbol enraizado (cuya raíz es T: raíz) que tiene las siguientes propiedades:

1) Todo nodo *x* tiene los siguientes atributos:
    a) *x.n*, el numero de claves actualmente almacenadas en el nodo *x*,
    b) las mismas *x.n*, *x.key1,...,x.key*